{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3.8.9 64-bit"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.8.9","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"interpreter":{"hash":"aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","execution_count":null,"source":["from IPython.display import clear_output\n","try:\n","    import albumentations\n","except ImportError:\n","    !pip install albumentations\n","\n","try:\n","    import Cython\n","except ImportError:\n","    !pip install Cython\n","clear_output()"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-08-22T12:29:29.047694Z","iopub.execute_input":"2021-08-22T12:29:29.048221Z","iopub.status.idle":"2021-08-22T12:29:44.403303Z","shell.execute_reply.started":"2021-08-22T12:29:29.048091Z","shell.execute_reply":"2021-08-22T12:29:44.40229Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["import json\n","from torch.utils.data import Dataset, DataLoader\n","from skimage import io\n","import pandas as pd\n","import torch\n","import os\n","import numpy as np\n","from pathlib import Path\n","import cv2, zlib, base64\n","from PIL import Image\n","import torch.nn as nn\n","import torchvision.transforms.functional as TF\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","from tqdm import tqdm\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-08-22T12:29:44.404847Z","iopub.execute_input":"2021-08-22T12:29:44.405173Z","iopub.status.idle":"2021-08-22T12:29:47.96636Z","shell.execute_reply.started":"2021-08-22T12:29:44.40514Z","shell.execute_reply":"2021-08-22T12:29:47.965169Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["# dataset.py\n","\n","class FootballBannerDataset(Dataset):\n","    \"\"\"Football advertising banners images from UEFA Champions League matches.\"\"\"\n","\n","    def __init__(self, image_dir: str, mask_dir: str, transform=None):\n","        \"\"\"\n","        Args:\n","            mask_dir (string): Directory with all the annotations.\n","            image_dir (string): Directory with all the images.\n","            transform (callable, optional): Optional transform to be applied\n","                on a sample.\n","        \"\"\"\n","        self.image_dir = image_dir\n","        self.mask_dir = mask_dir\n","        self.transform = transform\n","        self.images = os.listdir(image_dir)\n","\n","    def __len__(self):\n","        return len(self.images)\n","    \n","    def extract_mask(self, labels):\n","        mask = np.zeros((labels['size']['height'], labels['size']['width']), dtype=np.float32)\n","        if len(labels[\"objects\"]) == 0:\n","            return mask\n","        bitmap = labels[\"objects\"][0][\"bitmap\"][\"data\"]\n","        start_point = labels[\"objects\"][0][\"bitmap\"][\"origin\"]\n","\n","        mask_small = base64_2_mask(bitmap)\n","        mask[\n","            start_point[1] : start_point[1] + mask_small.shape[0],\n","            start_point[0] : start_point[0] + mask_small.shape[1],\n","        ] = mask_small\n","\n","        mask[mask == 255.0] = 1.0\n","        return mask\n","\n","    def __getitem__(self, idx):\n","        if torch.is_tensor(idx):\n","            idx = idx.tolist()\n","        \n","        #Â Read Image\n","        img_path = os.path.join(self.image_dir, self.images[idx])\n","        mask_path = os.path.join(self.mask_dir, self.images[idx]+\".json\")\n","        image = np.array(Image.open(img_path).convert(\"RGB\"))\n","        \n","        \n","        with open(mask_path, \"r\", encoding=\"utf-8\") as annotReader:\n","            labels = json.loads(annotReader.read())\n","        mask = self.extract_mask(labels)\n","\n","        if self.transform is not None:\n","            augmentations = self.transform(image=image, mask=mask)\n","            image = augmentations[\"image\"]\n","            mask = augmentations[\"mask\"]\n","\n","        return image, mask"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-08-22T12:29:47.968546Z","iopub.execute_input":"2021-08-22T12:29:47.968968Z","iopub.status.idle":"2021-08-22T12:29:47.984319Z","shell.execute_reply.started":"2021-08-22T12:29:47.968928Z","shell.execute_reply":"2021-08-22T12:29:47.982746Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["# model.py\n","\n","class DoubleConv(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super(DoubleConv, self).__init__()\n","        self.conv = nn.Sequential(\n","            nn.Conv2d(in_channels, out_channels, 3, 1, 1, bias=False),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True),\n","        )\n","\n","    def forward(self, x):\n","        return self.conv(x)\n","\n","\n","class UNET(nn.Module):\n","    def __init__(self, in_channels=3, out_channels=1, features=[64, 128, 256, 512]):\n","        super(UNET, self).__init__()\n","        self.ups = nn.ModuleList()\n","        self.downs = nn.ModuleList()\n","        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n","\n","        # Down part of UNET\n","        for feature in features:\n","            self.downs.append(DoubleConv(in_channels, feature))\n","            in_channels = feature\n","\n","        # Up part of UNET\n","        for feature in features[::-1]:\n","            self.ups.append(\n","                nn.ConvTranspose2d(feature * 2, feature, kernel_size=2, stride=2)\n","            )\n","            self.ups.append(DoubleConv(feature * 2, feature))\n","\n","        # Bootleneck layer\n","        self.bottleneck = DoubleConv(features[-1], features[-1] * 2)\n","\n","        # Final conv\n","        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n","\n","    def forward(self, x):\n","\n","        # Down\n","        skip_connections = []\n","        for down in self.downs:\n","            x = down(x)\n","            skip_connections.append(x)\n","            x = self.pool(x)\n","\n","        x = self.bottleneck(x)\n","\n","        # Upper\n","        skip_connections = skip_connections[::-1]\n","        for idx in range(0, len(self.ups), 2):\n","            x = self.ups[idx](x)\n","            skip_connection = skip_connections[idx // 2]\n","            if x.shape != skip_connection.shape:\n","                x = TF.resize(x, size=skip_connection.shape[2:])\n","            concat_skip = torch.cat((skip_connection, x), dim=1)\n","            x = self.ups[idx + 1](concat_skip)\n","\n","        return self.final_conv(x)\n"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-08-22T12:29:47.988589Z","iopub.execute_input":"2021-08-22T12:29:47.988999Z","iopub.status.idle":"2021-08-22T12:29:48.007259Z","shell.execute_reply.started":"2021-08-22T12:29:47.988965Z","shell.execute_reply":"2021-08-22T12:29:48.006029Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["# utils.py\n","\n","def base64_2_mask(s):\n","    z = zlib.decompress(base64.b64decode(s))\n","    n = np.frombuffer(z, np.uint8)\n","    mask = cv2.imdecode(n, cv2.IMREAD_UNCHANGED)[:, :, 3].astype(bool)\n","    return mask\n","\n","\n","def mask_2_base64(mask):\n","    img_pil = Image.fromarray(np.array(mask, dtype=np.uint8))\n","    img_pil.putpalette([0, 0, 0, 255, 255, 255])\n","    bytes_io = io.BytesIO()\n","    img_pil.save(bytes_io, format=\"PNG\", transparency=0, optimize=0)\n","    bytes = bytes_io.getvalue()\n","    return base64.b64encode(zlib.compress(bytes)).decode(\"utf-8\")\n","\n","\n","def save_checkpoint(state, filename=\"my_checkpoint.pth.tar\"):\n","    print(\"=> Saving checkpoint\")\n","    torch.save(state, filename)\n","\n","\n","def load_checkpoint(checkpoint, model):\n","    print(\"=> Loading checkpoint\")\n","    model.load_state_dict(checkpoint[\"state_dict\"])\n","\n","\n","def get_loaders(\n","    train_dir,\n","    train_maskdir,\n","    batch_size,\n","    train_transform,\n","    num_workers=4,\n","    pin_memory=True,\n","):\n","    footballBannerDataset = FootballBannerDataset(\n","        image_dir=train_dir,\n","        mask_dir=train_maskdir,\n","        transform=train_transform,\n","    )\n","    train_ds, val_ds = torch.utils.data.random_split(footballBannerDataset, [7000, 1851])\n","\n","    train_loader = DataLoader(\n","        train_ds,\n","        batch_size=batch_size,\n","        num_workers=num_workers,\n","        pin_memory=pin_memory,\n","        shuffle=True,\n","    )\n","\n","    val_loader = DataLoader(\n","        val_ds,\n","        batch_size=batch_size,\n","        num_workers=num_workers,\n","        pin_memory=pin_memory,\n","        shuffle=False,\n","    )\n","\n","    return train_loader, val_loader\n","\n","\n","def check_accuracy(loader, model, device=\"cuda\"):\n","    num_correct = 0\n","    num_pixels = 0\n","    dice_score = 0\n","    model.eval()\n","\n","    with torch.no_grad():\n","        for x, y in loader:\n","            x = x.to(device)\n","            y = y.to(device).unsqueeze(1)\n","            preds = torch.sigmoid(model(x))\n","            preds = (preds > 0.5).float()\n","            num_correct += (preds == y).sum()\n","            num_pixels += torch.numel(preds)\n","            dice_score += (2 * (preds * y).sum()) / ((preds + y).sum() + 1e-8)\n","\n","    print(f\"Got {num_correct}/{num_pixels} with acc {num_correct/num_pixels*100:.2f}\")\n","    print(f\"Dice score: {dice_score/len(loader)}\")\n","    model.train()\n","\n","\n","def save_predictions_as_imgs(loader, model, folder=\"saved_images\", device=\"cuda\"):\n","    model.eval()\n","    for idx, (x, y) in enumerate(loader):\n","        x = x.to(device=device)\n","        with torch.no_grad():\n","            preds = torch.sigmoid(model(x))\n","            preds = (preds > 0.5).float()\n","        if not os.path.exists(folder):\n","            !mkdir $folder\n","        torchvision.utils.save_image(preds, f\"{folder}/pred_{idx}.png\")\n","        torchvision.utils.save_image(y.unsqueeze(1), f\"{folder}/{idx}.png\")\n","\n","    model.train()\n"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-08-22T12:29:48.009161Z","iopub.execute_input":"2021-08-22T12:29:48.010128Z","iopub.status.idle":"2021-08-22T12:29:48.044817Z","shell.execute_reply.started":"2021-08-22T12:29:48.01007Z","shell.execute_reply":"2021-08-22T12:29:48.043729Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["# train.py\n","\n","\n","def train_fn(loader, model, optimizer, loss_fn, scaler, scheduler=None):\n","    \"\"\"Does one epoch of training.\"\"\"\n","    loop = tqdm(loader)\n","\n","    for batch_idx, (data, targets) in enumerate(loop):\n","        data = data.to(device=DEVICE)\n","        targets = targets.float().unsqueeze(1).to(device=DEVICE)\n","\n","        # forward\n","        with torch.cuda.amp.autocast():\n","            predictions = model(data)\n","            loss = loss_fn(predictions, targets)\n","\n","        # backward\n","        optimizer.zero_grad()\n","        scaler.scale(loss).backward()\n","        scaler.step(optimizer)\n","        scaler.update()\n","\n","        # Update tqdm loop\n","        loop.set_postfix(loss=loss.item())\n","\n","\n","def main():\n","    train_transform = A.Compose(\n","        [\n","            A.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n","            A.Rotate(limit=35, p=1.0),\n","            A.HorizontalFlip(p=0.5),\n","            A.VerticalFlip(p=0.1),\n","            A.Normalize(\n","                mean=[0.0, 0.0, 0.0],\n","                std=[1.0, 1.0, 1.0],\n","                max_pixel_value=255.0,\n","            ),\n","            ToTensorV2(),\n","        ],\n","    )\n","\n","    model = UNET(in_channels=3, out_channels=1).to(DEVICE)\n","    loss_fn = nn.BCEWithLogitsLoss()  # cross entropy loss\n","    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n","\n","    train_loader, val_loader = get_loaders(\n","        TRAIN_IMG_DIR,\n","        TRAIN_MASK_DIR,\n","        BATCH_SIZE,\n","        train_transform,\n","        NUM_WORKERS,\n","        PIN_MEMORY,\n","    )\n","\n","    if LOAD_MODEL:\n","        load_checkpoint(torch.load(\"../input/unet-football-banner-image-segmentation/my_checkpoint.pth.tar\"), model)\n","\n","    check_accuracy(val_loader, model, device=DEVICE)\n","    scaler = torch.cuda.amp.GradScaler()\n","\n","\n","    for epoch in range(NUM_EPOCHS):\n","        train_fn(train_loader, model, optimizer, loss_fn, scaler)\n","\n","        # save model\n","        checkpoint = {\n","            \"state_dict\": model.state_dict(),\n","            \"optimizer\": optimizer.state_dict(),\n","        }\n","        save_checkpoint(checkpoint)\n","\n","        # check accuracy\n","        check_accuracy(val_loader, model, device=DEVICE)\n","\n","        # print some examples to a folder\n","        save_predictions_as_imgs(\n","            val_loader, model, folder=\"saved_images/\", device=DEVICE\n","        )"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-08-22T12:29:48.046443Z","iopub.execute_input":"2021-08-22T12:29:48.047343Z","iopub.status.idle":"2021-08-22T12:29:48.069333Z","shell.execute_reply.started":"2021-08-22T12:29:48.047228Z","shell.execute_reply":"2021-08-22T12:29:48.067072Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["meta_class_data = {\n","    \"mastercard\": 0,\n","    \"nissan\": 1,\n","    \"playstation\": 2,\n","    \"unicredit\": 3,\n","    \"pepsi\": 4,\n","    \"adidas\": 5,\n","    \"gazprom\": 6,\n","    \"heineken\": 7,\n","}\n","\n","# Hyperparameters etc.\n","LEARNING_RATE = 1e-4\n","DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","BATCH_SIZE = 32  # 32\n","NUM_EPOCHS = 100  # 100\n","NUM_WORKERS = 2\n","IMAGE_HEIGHT = 160  # 1280 originally\n","IMAGE_WIDTH = 240  # 1918 originally\n","PIN_MEMORY = True\n","LOAD_MODEL = True\n","TRAIN_IMG_DIR = \"../input/football-advertising-banners-detection/football/images\"\n","TRAIN_MASK_DIR = \"../input/football-advertising-banners-detection/football/annotations\""],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-08-22T12:29:48.07224Z","iopub.execute_input":"2021-08-22T12:29:48.072987Z","iopub.status.idle":"2021-08-22T12:29:48.089375Z","shell.execute_reply.started":"2021-08-22T12:29:48.072922Z","shell.execute_reply":"2021-08-22T12:29:48.087666Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["# Train Model\n","main()"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-08-22T12:29:48.092349Z","iopub.execute_input":"2021-08-22T12:29:48.092954Z","iopub.status.idle":"2021-08-22T12:29:48.105651Z","shell.execute_reply.started":"2021-08-22T12:29:48.092867Z","shell.execute_reply":"2021-08-22T12:29:48.104504Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["model = UNET(in_channels=3, out_channels=1).to(DEVICE)\n","load_checkpoint(torch.load(\"./my_checkpoint.pth.tar\"), model)"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-08-22T12:37:08.029253Z","iopub.execute_input":"2021-08-22T12:37:08.029907Z","iopub.status.idle":"2021-08-22T12:37:08.698148Z","shell.execute_reply.started":"2021-08-22T12:37:08.02985Z","shell.execute_reply":"2021-08-22T12:37:08.696978Z"},"trusted":true}},{"cell_type":"markdown","source":["# Test on Example Case"],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["import matplotlib.pyplot as plt\n","from torchvision import transforms\n","\n","def pred(x, model):\n","    x = x.to(device=DEVICE)\n","    with torch.no_grad():\n","        preds = torch.sigmoid(model(x))\n","        preds = (preds > 0.5).float()\n","    return preds\n","\n","ex_img_path1 =\"../input/football-advertising-banners-detection/football/images/00bhhxx56ft6rtq.png\"\n","ex_img_path2 = \"../input/football-advertising-banners-detection/football/images/00fkgxlxff8hd3z.png\"\n","fig, axes = plt.subplots(2,1,figsize=(8,20))\n","ax1,ax2 = axes\n","\n","\n","fig.suptitle(\"Example Model Predictions\", fontsize=24)\n","\n","# Image 1\n","img=Image.open(ex_img_path1)\n","ax1.set_title(\"Example Image from GAL - BRU\", fontsize=20)\n","ax1.imshow(img)\n","mask_tensor = pred(transforms.ToTensor()(img).unsqueeze_(0),model)\n","mask = transforms.ToPILImage()(mask_tensor.squeeze_(0))\n","ax1.imshow(mask, cmap='jet', alpha=0.5)\n","\n","# Image 2\n","img=Image.open(ex_img_path2)\n","ax2.set_title(\"Example Image from GAL - BRU\", fontsize=20)\n","ax2.imshow(img)\n","mask_tensor = pred(transforms.ToTensor()(img).unsqueeze_(0),model)\n","mask = transforms.ToPILImage()(mask_tensor.squeeze_(0))\n","ax2.imshow(mask, cmap='jet', alpha=0.5)\n","plt.tight_layout()"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-08-22T13:05:26.800636Z","iopub.execute_input":"2021-08-22T13:05:26.801094Z","iopub.status.idle":"2021-08-22T13:05:56.132662Z","shell.execute_reply.started":"2021-08-22T13:05:26.801059Z","shell.execute_reply":"2021-08-22T13:05:56.131449Z"},"trusted":true}}]}